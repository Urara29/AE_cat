{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Urara29/AE_cat/blob/main/AE_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8H0BHux39m8i"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from copy import deepcopy\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Conv2DTranspose, Activation, Flatten, Dropout, Reshape, GlobalAveragePooling2D, MaxPooling2D\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mr-ohX5E062"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#カレントディレクトリに移動\n",
        "%cd \"/content/drive/My Drive/sotsuron/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2L143Zn6Ql8L",
        "outputId": "38970506-0125-4cce-fc44-b6ac4fbc6f2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/sotsuron\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install chromium-chromedriver"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPE0MMSuvRf_",
        "outputId": "a5cf1018-985a-494b-fc04-456130cb04e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (107.0.5304.87-0ubuntu11.18.04.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 5 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install icrawler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFT9g5u6v4yy",
        "outputId": "0971921d-5866-440c-e960-8b67e2a25eba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: icrawler in /usr/local/lib/python3.7/dist-packages (0.6.6)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from icrawler) (4.6.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from icrawler) (7.1.2)\n",
            "Requirement already satisfied: requests>=2.9.1 in /usr/local/lib/python3.7/dist-packages (from icrawler) (2.23.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from icrawler) (4.9.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from icrawler) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.1->icrawler) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.1->icrawler) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.1->icrawler) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.1->icrawler) (2022.9.24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[In]\n",
        "from icrawler.builtin import BingImageCrawler\n",
        "import os\n",
        "\n",
        "searchkeywords = '猫正面写真' # 検索するキーワード\n",
        "savedir = 'photos_cats' # 画像を保存するディレクトリ\n",
        "counts = 500 # 収集するデータ数\n",
        "\n",
        "def getimages(q=searchkeywords, maxnum=counts, save_dir=savedir):\n",
        "   if not os.path.exists(savedir): # ディレクトリがなければ作る\n",
        "       os.mkdir(savedir)\n",
        "       print(f'{savedir}フォルダを作成しました。')\n",
        "       \n",
        "   bing_crawler = BingImageCrawler(storage={'root_dir': save_dir})\n",
        "   bing_crawler.crawl(keyword=q, max_num=maxnum, filters=None) #filtersでは画像のサイズやタイプを指定可能\n",
        "   \n",
        "getimages(q=searchkeywords, maxnum=counts, save_dir=savedir)    "
      ],
      "metadata": {
        "id": "URoz4u6EWfOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "\n",
        "WH_RATIO = 1 / 1\n",
        "RESIZE_W = 128\n",
        "\n",
        "\n",
        "def main(argv):\n",
        "    for tgt in argv[1:]:\n",
        "        if os.path.isdir(tgt):\n",
        "            for f in os.listdir(tgt):\n",
        "                tp = os.path.join(tgt, f)\n",
        "                if not os.path.isdir(tp):\n",
        "                    edit_image(tp)\n",
        "        else:\n",
        "            edit_image(tgt)\n",
        "\n",
        "\n",
        "def edit_image(fp):\n",
        "    try:\n",
        "        img = Image.open(fp)\n",
        "        img_ratio = img.width / img.height\n",
        "\n",
        "        if img_ratio > WH_RATIO:\n",
        "            crop_pixel = (img.width - img.height * WH_RATIO) / 2\n",
        "            left = int(crop_pixel)\n",
        "            right = img.width - int(crop_pixel)\n",
        "            upper = 0\n",
        "            lower = img.height\n",
        "\n",
        "            img = img.crop((left, upper, right, lower))\n",
        "\n",
        "        if img.width > RESIZE_W:\n",
        "            img = img.resize((RESIZE_W, int(RESIZE_W * img.height / img.width)))\n",
        "\n",
        "        dst_dir = os.path.join(os.path.dirname(fp), 'trim')\n",
        "\n",
        "        if not os.path.exists(dst_dir):\n",
        "            os.mkdir(dst_dir)\n",
        "\n",
        "        img.save(os.path.join(dst_dir, os.path.basename(fp)))\n",
        "\n",
        "    except UnidentifiedImageError:\n",
        "        pass\n",
        "    except FileNotFoundError:\n",
        "        pass\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main(sys.argv)"
      ],
      "metadata": {
        "id": "FGWFD-Lb8Fdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#リサイズ処理\n",
        "# -*- coding: utf-8 -*-\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "#パラメータ\n",
        "#======================================\n",
        "#画像を保存してあるフォルダ名\n",
        "f = 'photos_cats/'\n",
        "#リサイズした画像を保存するフォルダ名\n",
        "f_resize = 'cat_resize/'\n",
        "#リサイズ後のサイズ\n",
        "size = 128\n",
        "#======================================\n",
        "\n",
        "#処理\n",
        "#======================================\n",
        "if not os.path.isdir(f_resize):\n",
        "    os.makedirs(f_resize)\n",
        "files = os.listdir(f)\n",
        "for file in files:\n",
        "    img = Image.open(f + file).convert(\"RGBA\"); img.close\n",
        "    \n",
        "    tmp = np.array(img)\n",
        "    \n",
        "    mask = tmp[:,:,3] < 240\n",
        "    tmp[mask, 0] = 255\n",
        "    tmp[mask, 1] = 255\n",
        "    tmp[mask, 2] = 255\n",
        "    \n",
        "    img = Image.fromarray(tmp[:,:,0:3])\n",
        "    \n",
        "    width, height = img.size\n",
        "    if width == height:\n",
        "        tmp = img\n",
        "    elif width > height:\n",
        "        tmp = Image.new('RGB', (width, width), (255, 255, 255))\n",
        "        tmp.paste(img, (0, (width - height) // 2))\n",
        "    else:\n",
        "        tmp = Image.new('RGB', (height, height), (255, 255, 255))\n",
        "        tmp.paste(img, ((height - width) // 2, 0))\n",
        "    img_resize = tmp.resize((size, size), Image.BICUBIC)\n",
        "    img_resize.save(f_resize + file)\n",
        "    print(\"リサイズ完了\")\n",
        "print()\n",
        "#======================================"
      ],
      "metadata": {
        "id": "FMhl9-KCajMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXcmrlt5Bzt6"
      },
      "outputs": [],
      "source": [
        "#パラメータ\n",
        "\n",
        "#教師画像の親フォルダ\n",
        "f = '/content/drive/MyDrive/Colab Notebooks/sotsuron/cat_resize/'\n",
        "\n",
        "#ミニバッチサイズ（教師データ数の公約数にしてください）\n",
        "batch_size = 40\n",
        "\n",
        "#乱数列の次元\n",
        "z_dim = 100\n",
        "\n",
        "#discriminatorの学習率\n",
        "opt = keras.optimizers.Adam(lr=0.0002)\n",
        "\n",
        "#画像を保存するフォルダ\n",
        "img_f = '/content/drive/MyDrive/Colab Notebooks/sotsuron/AE_img/'\n",
        "#重みを保存するフォルダ\n",
        "para_f = '/content/drive/MyDrive/Colab Notebooks/sotsuron/AE_para/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4Z3wAi1CZgN"
      },
      "outputs": [],
      "source": [
        "#教師データ読み込み\n",
        "x_train = []\n",
        "files = os.listdir(f)\n",
        "for file in files:\n",
        "    img = Image.open(f + file).convert(\"RGB\"); img.close\n",
        "    x_train.append(np.array(img))\n",
        "x_train = np.array(x_train)\n",
        "\n",
        "#-1～+1に規格化\n",
        "x_train = (x_train - 127.5) / 127.5\n",
        "\n",
        "#確認用に手前の10枚を隔離\n",
        "x_check = deepcopy(x_train[:10])\n",
        "x_train = x_train[10:]\n",
        "\n",
        "#入力と出力は同じですよ\n",
        "y_train = x_train\n",
        "\n",
        "print('枚数, たて, よこ, チャンネル')\n",
        "print(x_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3elwM0hHaxK"
      },
      "outputs": [],
      "source": [
        "#モデルの定義\n",
        "\n",
        "def encoder_model():\n",
        "    model = Sequential()\n",
        "    \n",
        "    #128*128*3ch → 64*64*32chにたたむ\n",
        "    model.add(Conv2D(32, (4, 4), strides=(2, 2), padding='same', input_shape=(128, 128, 3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "    \n",
        "    #64*64*32ch → 32*32*64chにたたむ\n",
        "    model.add(Conv2D(64, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "    \n",
        "    #32*32*64ch → 16*16*128chにたたむ\n",
        "    model.add(Conv2D(128, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "    \n",
        "    #16*16*128ch → 8*8*256chにたたむ\n",
        "    model.add(Conv2D(256, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "    \n",
        "    #フラットに伸ばして\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.5))\n",
        "    \n",
        "    #100次元まで圧縮\n",
        "    model.add(Dense(z_dim))\n",
        "    model.add(Activation('tanh'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "def decoder_model():\n",
        "    model = Sequential()\n",
        "    \n",
        "    \n",
        "    #100次元 → 8*8*256=16384次元に展開\n",
        "    model.add(Dense(8*8*256, input_shape=(z_dim, )))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "    \n",
        "    #8*8*256chに変形\n",
        "    model.add(Reshape((8, 8, 256)))\n",
        "    model.add(Dropout(0.5))\n",
        "    \n",
        "    #8*8*256ch → 16*16*128chにアップ\n",
        "    model.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "    \n",
        "    #16*16*128ch → 32*32*64chにアップ\n",
        "    model.add(Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "    \n",
        "    #32*32*64ch → 64*64*32chにアップ\n",
        "    model.add(Conv2DTranspose(32, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "    \n",
        "    #64*64*32ch → 128*128*3chにアップ\n",
        "    model.add(Conv2DTranspose(3, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(Activation('tanh'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "def autoencoder_model(encoder, decoder):\n",
        "    model = Sequential()\n",
        "    model.add(encoder)\n",
        "    model.add(decoder)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgzXPouQK3Dm"
      },
      "outputs": [],
      "source": [
        "#モデルの生成\n",
        "\n",
        "#encoderの生成\n",
        "encoder = encoder_model()\n",
        "encoder.summary()\n",
        "#decoderの生成\n",
        "decoder = decoder_model()\n",
        "decoder.summary()\n",
        "#autoencoderの作成\n",
        "autoencoder = autoencoder_model(encoder, decoder)\n",
        "autoencoder.summary()\n",
        "\n",
        "#autoencoderのコンパイル\n",
        "autoencoder.compile(loss='msle', optimizer=opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOsHKuMgK-8L"
      },
      "outputs": [],
      "source": [
        "#保存用フォルダ作成\n",
        "if not os.path.isdir(para_f): \n",
        "    os.makedirs(para_f)\n",
        "if not os.path.isdir(img_f): \n",
        "    os.makedirs(img_f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpNji_0cLEsY"
      },
      "outputs": [],
      "source": [
        "#学習中のログ\n",
        "#======================================\n",
        "class EpisodeLogger(keras.callbacks.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        \n",
        "        #一定epoch毎に画像表示\n",
        "        if epoch % 10 == 0:\n",
        "            #======================================\n",
        "            x_ans = autoencoder.predict(x_check)\n",
        "\n",
        "            stack1 = np.concatenate(x_check, axis=1)\n",
        "            stack2 = np.concatenate(x_ans, axis=1)\n",
        "            stack3 = np.concatenate([stack1, stack2], axis=0)\n",
        "            img = Image.fromarray(np.uint8(stack3 * 127.5 + 127.5))\n",
        "\n",
        "            plt.figure(figsize=(10, 10))\n",
        "            img.save(img_f + str(epoch) + '.png')\n",
        "            plt.imshow(img, vmin = 0, vmax = 255)\n",
        "            plt.show()\n",
        "            #======================================\n",
        "        \n",
        "        #一定epoch毎に重みを保存\n",
        "        if epoch % 50 == 0:\n",
        "            #重みの保存\n",
        "            encoder.save(para_f + 'encoder_' + str(epoch) + '.h5')\n",
        "            decoder.save(para_f + 'decoder_' + str(epoch) + '.h5')\n",
        "#======================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iN7Eh1G5LHmb"
      },
      "outputs": [],
      "source": [
        "#学習\n",
        "hist = autoencoder.fit(x_train, y_train, epochs=30000, batch_size=batch_size, verbose=2, callbacks=[EpisodeLogger()])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}